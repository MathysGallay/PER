{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a18c396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Repo clon√©/trouv√©: C:\\Users\\mathy\\Documents\\SI5\\PER\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Clone le repo PER depuis GitHub\n",
    "# Note: Pour environnement local, utilise le chemin direct. Pour Kaggle/Colab, adapte avec token si priv√©.\n",
    "\n",
    "repo_path = \"/kaggle/working/PER\" if \"/kaggle\" in os.getcwd() else \"C:\\\\Users\\\\mathy\\\\Documents\\\\SI5\\\\PER\"\n",
    "\n",
    "if not os.path.exists(repo_path):\n",
    "    # Pour repos priv√©, utilise: git clone https://<TOKEN>@github.com/MathysGallay/PER.git\n",
    "    subprocess.run([\"git\", \"clone\", \"https://github.com/MathysGallay/PER.git\", repo_path], check=True)\n",
    "\n",
    "os.chdir(repo_path)\n",
    "print(f\"‚úì Repo clon√©/trouv√©: {repo_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26a446fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source exists: True\n",
      "Labels exist: True\n",
      "Images trouv√©es : 2500\n",
      "Train: 2000, Val: 500\n",
      "‚úì Dataset YOLO cr√©√©\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Chemins adapt√©s (local ou Kaggle)\n",
    "base_path = \"/kaggle/working/PER\" if \"/kaggle\" in os.getcwd() else \".\"\n",
    "SOURCE_DIR = os.path.join(base_path, \"thermal_coco/augmented\")\n",
    "SOURCE_LABELS = os.path.join(base_path, \"mini_coco/labels\")\n",
    "TARGET_DIR = \"thermal_yolo\"\n",
    "\n",
    "print(f\"Source exists: {os.path.exists(SOURCE_DIR)}\")\n",
    "print(f\"Labels exist: {os.path.exists(SOURCE_LABELS)}\")\n",
    "\n",
    "os.makedirs(TARGET_DIR, exist_ok=True)\n",
    "\n",
    "# YOLO folders\n",
    "folders = [\"images/train\", \"images/val\", \"labels/train\", \"labels/val\"]\n",
    "for f in folders:\n",
    "    os.makedirs(os.path.join(TARGET_DIR, f), exist_ok=True)\n",
    "\n",
    "# R√©cup√©rer toutes les images\n",
    "images = glob.glob(os.path.join(SOURCE_DIR, \"*.jpg\"))\n",
    "print(f\"Images trouv√©es : {len(images)}\")\n",
    "\n",
    "if len(images) == 0:\n",
    "    print(\"ERREUR : Aucune image trouv√©e!\")\n",
    "else:\n",
    "    # Train/val split\n",
    "    train_ratio = 0.8\n",
    "    random.shuffle(images)\n",
    "    split = int(len(images) * train_ratio)\n",
    "    \n",
    "    train_imgs = images[:split]\n",
    "    val_imgs = images[split:]\n",
    "    \n",
    "    print(f\"Train: {len(train_imgs)}, Val: {len(val_imgs)}\")\n",
    "    \n",
    "    # Copier train\n",
    "    for img_path in train_imgs:\n",
    "        img_name = os.path.basename(img_path)\n",
    "        shutil.copy(img_path, os.path.join(TARGET_DIR, \"images/train\", img_name))\n",
    "        \n",
    "        base_name = img_name.split('_aug')[0] if '_aug' in img_name else img_name.replace('.jpg', '')\n",
    "        label_src = os.path.join(SOURCE_LABELS, base_name + '.txt')\n",
    "        label_dst = os.path.join(TARGET_DIR, \"labels/train\", img_name.replace('.jpg', '.txt'))\n",
    "        \n",
    "        if os.path.exists(label_src):\n",
    "            shutil.copy(label_src, label_dst)\n",
    "    \n",
    "    # Copier val\n",
    "    for img_path in val_imgs:\n",
    "        img_name = os.path.basename(img_path)\n",
    "        shutil.copy(img_path, os.path.join(TARGET_DIR, \"images/val\", img_name))\n",
    "        \n",
    "        base_name = img_name.split('_aug')[0] if '_aug' in img_name else img_name.replace('.jpg', '')\n",
    "        label_src = os.path.join(SOURCE_LABELS, base_name + '.txt')\n",
    "        label_dst = os.path.join(TARGET_DIR, \"labels/val\", img_name.replace('.jpg', '.txt'))\n",
    "        \n",
    "        if os.path.exists(label_src):\n",
    "            shutil.copy(label_src, label_dst)\n",
    "    \n",
    "    print(\"‚úì Dataset YOLO cr√©√©\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ce0bdf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes animales : ['bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe']\n",
      "‚úì data.yaml g√©n√©r√© !\n"
     ]
    }
   ],
   "source": [
    "# D√©finir les classes animales\n",
    "ANIMAL_CLASSES = {\n",
    "    14: \"bird\",\n",
    "    15: \"cat\",\n",
    "    16: \"dog\",\n",
    "    17: \"horse\",\n",
    "    18: \"sheep\",\n",
    "    19: \"cow\",\n",
    "    20: \"elephant\",\n",
    "    21: \"bear\",\n",
    "    22: \"zebra\",\n",
    "    23: \"giraffe\",\n",
    "}\n",
    "\n",
    "classes = list(ANIMAL_CLASSES.values())\n",
    "print(f\"Classes animales : {classes}\")\n",
    "\n",
    "yaml_content = f\"\"\"\n",
    "train: {TARGET_DIR}/images/train\n",
    "val: {TARGET_DIR}/images/val\n",
    "\n",
    "nc: {len(classes)}\n",
    "names: {classes}\n",
    "\"\"\"\n",
    "\n",
    "with open(\"data.yaml\", \"w\") as f:\n",
    "    f.write(yaml_content)\n",
    "\n",
    "print(\"‚úì data.yaml g√©n√©r√© !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8efbe90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.240 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.233  Python-3.10.19 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=False, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=True, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=416, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=thermal_exp_improved, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs/train, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\mathy\\Documents\\SI5\\PER\\runs\\train\\thermal_exp_improved, save_frames=False, save_json=False, save_period=10, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=10\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2119918  ultralytics.nn.modules.head.Detect           [10, [128, 256, 512]]         \n",
      "Model summary: 129 layers, 11,139,470 parameters, 11,139,454 gradients, 28.7 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 145.055.7 MB/s, size: 26.6 KB)\n",
      "\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\mathy\\Documents\\SI5\\PER\\thermal_yolo\\labels\\train... 94 images, 0 backgrounds, 0 corrupt: 4% ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 94/2497 270.9it/s 0.1s<8.9s\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\mathy\\Documents\\SI5\\PER\\thermal_yolo\\labels\\train... 231 images, 0 backgrounds, 0 corrupt: 9% ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 231/2497 584.3it/s 0.2s<3.9s\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\mathy\\Documents\\SI5\\PER\\thermal_yolo\\labels\\train... 379 images, 0 backgrounds, 0 corrupt: 15% ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 379/2497 835.2it/s 0.3s<2.5s\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\mathy\\Documents\\SI5\\PER\\thermal_yolo\\labels\\train... 542 images, 0 backgrounds, 0 corrupt: 22% ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 542/2497 1.1Kit/s 0.4s<1.9s\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\mathy\\Documents\\SI5\\PER\\thermal_yolo\\labels\\train... 695 images, 0 backgrounds, 0 corrupt: 28% ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 695/2497 1.2Kit/s 0.5s<1.5s\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\mathy\\Documents\\SI5\\PER\\thermal_yolo\\labels\\train... 844 images, 0 backgrounds, 0 corrupt: 34% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 844/2497 1.3Kit/s 0.6s<1.3s\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\mathy\\Documents\\SI5\\PER\\thermal_yolo\\labels\\train... 962 images, 0 backgrounds, 0 corrupt: 39% ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 962/2497 1.2Kit/s 0.7s<1.3s\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\mathy\\Documents\\SI5\\PER\\thermal_yolo\\labels\\train... 1124 images, 0 backgrounds, 0 corrupt: 45% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 1124/2497 1.3Kit/s 0.8s<1.0s\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\mathy\\Documents\\SI5\\PER\\thermal_yolo\\labels\\train... 1275 images, 0 backgrounds, 0 corrupt: 51% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 1275/2497 1.4Kit/s 0.9s<0.9s\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\mathy\\Documents\\SI5\\PER\\thermal_yolo\\labels\\train... 1449 images, 0 backgrounds, 0 corrupt: 58% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 1449/2497 1.5Kit/s 1.0s<0.7s\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\mathy\\Documents\\SI5\\PER\\thermal_yolo\\labels\\train... 1606 images, 0 backgrounds, 0 corrupt: 64% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ 1606/2497 1.5Kit/s 1.1s<0.6s\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\mathy\\Documents\\SI5\\PER\\thermal_yolo\\labels\\train... 1728 images, 0 backgrounds, 0 corrupt: 69% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ 1728/2497 1.4Kit/s 1.2s<0.6s\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\mathy\\Documents\\SI5\\PER\\thermal_yolo\\labels\\train... 1830 images, 0 backgrounds, 0 corrupt: 73% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ 1830/2497 1.3Kit/s 1.4s<0.5s\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\mathy\\Documents\\SI5\\PER\\thermal_yolo\\labels\\train... 1969 images, 0 backgrounds, 0 corrupt: 79% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ 1969/2497 1.3Kit/s 1.5s<0.4s\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\mathy\\Documents\\SI5\\PER\\thermal_yolo\\labels\\train... 2101 images, 0 backgrounds, 0 corrupt: 84% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ 2101/2497 1.3Kit/s 1.6s<0.3s\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\mathy\\Documents\\SI5\\PER\\thermal_yolo\\labels\\train... 2222 images, 0 backgrounds, 0 corrupt: 89% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ 2222/2497 1.2Kit/s 1.7s<0.2s\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\mathy\\Documents\\SI5\\PER\\thermal_yolo\\labels\\train... 2360 images, 0 backgrounds, 0 corrupt: 95% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ 2360/2497 1.2Kit/s 1.8s<0.1s\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\mathy\\Documents\\SI5\\PER\\thermal_yolo\\labels\\train... 2458 images, 0 backgrounds, 0 corrupt: 98% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏ 2458/2497 1.2Kit/s 1.9s<0.0s\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\mathy\\Documents\\SI5\\PER\\thermal_yolo\\labels\\train... 2497 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2497/2497 1.3Kit/s 1.9s\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\mathy\\Documents\\SI5\\PER\\thermal_yolo\\labels\\train... 2497 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2497/2497 1.3Kit/s 1.9s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\mathy\\Documents\\SI5\\PER\\thermal_yolo\\labels\\train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mathy\\anaconda3\\envs\\PER_GPU\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\mathy\\anaconda3\\envs\\PER_GPU\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\mathy\\anaconda3\\envs\\PER_GPU\\Scripts\\yolo.exe\\__main__.py\", line 6, in <module>\n",
      "  File \"C:\\Users\\mathy\\anaconda3\\envs\\PER_GPU\\lib\\site-packages\\ultralytics\\cfg\\__init__.py\", line 985, in entrypoint\n",
      "    getattr(model, mode)(**overrides)  # default args from model\n",
      "  File \"C:\\Users\\mathy\\anaconda3\\envs\\PER_GPU\\lib\\site-packages\\ultralytics\\engine\\model.py\", line 773, in train\n",
      "    self.trainer.train()\n",
      "  File \"C:\\Users\\mathy\\anaconda3\\envs\\PER_GPU\\lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 243, in train\n",
      "    self._do_train()\n",
      "  File \"C:\\Users\\mathy\\anaconda3\\envs\\PER_GPU\\lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 364, in _do_train\n",
      "    self._setup_train()\n",
      "  File \"C:\\Users\\mathy\\anaconda3\\envs\\PER_GPU\\lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 323, in _setup_train\n",
      "    self.train_loader = self.get_dataloader(\n",
      "  File \"C:\\Users\\mathy\\anaconda3\\envs\\PER_GPU\\lib\\site-packages\\ultralytics\\models\\yolo\\detect\\train.py\", line 93, in get_dataloader\n",
      "    dataset = self.build_dataset(dataset_path, mode, batch_size)\n",
      "  File \"C:\\Users\\mathy\\anaconda3\\envs\\PER_GPU\\lib\\site-packages\\ultralytics\\models\\yolo\\detect\\train.py\", line 77, in build_dataset\n",
      "    return build_yolo_dataset(self.args, img_path, batch, self.data, mode=mode, rect=mode == \"val\", stride=gs)\n",
      "  File \"C:\\Users\\mathy\\anaconda3\\envs\\PER_GPU\\lib\\site-packages\\ultralytics\\data\\build.py\", line 236, in build_yolo_dataset\n",
      "    return dataset(\n",
      "  File \"C:\\Users\\mathy\\anaconda3\\envs\\PER_GPU\\lib\\site-packages\\ultralytics\\data\\dataset.py\", line 88, in __init__\n",
      "    super().__init__(*args, channels=self.data.get(\"channels\", 3), **kwargs)\n",
      "  File \"C:\\Users\\mathy\\anaconda3\\envs\\PER_GPU\\lib\\site-packages\\ultralytics\\data\\base.py\", line 135, in __init__\n",
      "    if self.cache == \"ram\" and self.check_cache_ram():\n",
      "  File \"C:\\Users\\mathy\\anaconda3\\envs\\PER_GPU\\lib\\site-packages\\ultralytics\\data\\base.py\", line 330, in check_cache_ram\n",
      "    im = imread(random.choice(self.im_files))  # sample image\n",
      "  File \"C:\\Users\\mathy\\anaconda3\\envs\\PER_GPU\\lib\\site-packages\\ultralytics\\utils\\patches.py\", line 42, in imread\n",
      "    im = cv2.imdecode(file_bytes, flags)\n",
      "cv2.error: OpenCV(4.12.0) :-1: error: (-5:Bad argument) in function 'imdecode'\n",
      "> Overload resolution failed:\n",
      ">  - buf is not a numpy array, neither a scalar\n",
      ">  - Expected Ptr<cv::UMat> for argument 'buf'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Entra√Ænement optimis√© - Ultralytics CLI\n",
    "!yolo train \\\n",
    "    model=yolov8s.pt \\\n",
    "    data=data.yaml \\\n",
    "    imgsz=416 \\\n",
    "    batch=8 \\\n",
    "    epochs=100 \\\n",
    "    patience=10 \\\n",
    "    save_period=10 \\\n",
    "    name=thermal_exp_improved \\\n",
    "    project=runs/train \\\n",
    "    device=0 \\\n",
    "    cache=True \\\n",
    "    exist_ok=True \\\n",
    "    amp=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd1f9b2",
   "metadata": {},
   "source": [
    "## üìπ Alternative Dataset - Extraction YouTube\n",
    "\n",
    "Le dataset thermique actuel est artificiel et produit des r√©sultats limit√©s. Une meilleure approche est d'extraire des frames de **vid√©os YouTube r√©elles** (safaris thermiques, documentaires animaliers FLIR, etc.)\n",
    "\n",
    "**Avantages :**\n",
    "- Images thermiques authentiques\n",
    "- Vari√©t√© de conditions (jour/nuit, m√©t√©o, distances)\n",
    "- Qualit√© cam√©ra professionnelle (FLIR, cam√©ras militaires)\n",
    "\n",
    "**Sources sugg√©r√©es :**\n",
    "- \"thermal imaging safari africa\"\n",
    "- \"FLIR thermal camera wildlife\"\n",
    "- \"infrared animal detection night\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total : 0 frames extraites de 0 vid√©os\n",
      "Dossier : real_thermal_dataset/\n",
      "Script pr√™t. Ajoute des URLs YouTube dans YOUTUBE_URLS et d√©commente le code d'ex√©cution.\n",
      "Recherches sugg√©r√©es : 'thermal imaging safari', 'FLIR wildlife night', 'infrared animal detection'\n"
     ]
    }
   ],
   "source": [
    "# Installation des d√©pendances (d√©commenter si n√©cessaire)\n",
    "# !pip install yt-dlp opencv-python-headless\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "def extract_frames_from_youtube(video_url, output_dir=\"real_thermal_dataset\", fps=1, max_frames=500):\n",
    "    \"\"\"\n",
    "    Extrait des frames d'une vid√©o YouTube √† un FPS donn√©.\n",
    "    \n",
    "    Args:\n",
    "        video_url: URL YouTube (ex: \"https://www.youtube.com/watch?v=...\")\n",
    "        output_dir: Dossier de sortie pour les frames\n",
    "        fps: Nombre de frames par seconde √† extraire (1 = 1 frame/sec, 0.5 = 1 frame/2sec)\n",
    "        max_frames: Nombre maximal de frames √† extraire\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # T√©l√©charger la vid√©o avec yt-dlp\n",
    "    video_path = os.path.join(output_dir, \"temp_video.mp4\")\n",
    "    print(f\"T√©l√©chargement de la vid√©o...\")\n",
    "    try:\n",
    "        subprocess.run([\n",
    "            \"yt-dlp\",\n",
    "            \"-f\", \"best[height<=720]\",  # Max 720p pour √©conomiser bande passante\n",
    "            \"-o\", video_path,\n",
    "            video_url\n",
    "        ], check=True)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Erreur : yt-dlp n'est pas install√©. Lance : pip install yt-dlp\")\n",
    "        return 0\n",
    "    \n",
    "    # Extraire les frames\n",
    "    print(f\"üéûÔ∏è Extraction des frames (FPS={fps})...\")\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    video_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_interval = int(video_fps / fps)\n",
    "    \n",
    "    frame_count = 0\n",
    "    saved_count = 0\n",
    "    \n",
    "    while cap.isOpened() and saved_count < max_frames:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        if frame_count % frame_interval == 0:\n",
    "            frame_filename = os.path.join(output_dir, f\"frame_{saved_count:05d}.jpg\")\n",
    "            cv2.imwrite(frame_filename, frame, [cv2.IMWRITE_JPEG_QUALITY, 95])\n",
    "            saved_count += 1\n",
    "            \n",
    "            if saved_count % 50 == 0:\n",
    "                print(f\"  ‚úì {saved_count} frames extraites...\")\n",
    "        \n",
    "        frame_count += 1\n",
    "    \n",
    "    cap.release()\n",
    "    os.remove(video_path)  # Supprimer la vid√©o temporaire\n",
    "    \n",
    "    print(f\"‚úÖ Extraction termin√©e : {saved_count} frames dans {output_dir}\")\n",
    "    return saved_count\n",
    "\n",
    "# Exemple d'utilisation avec URLs YouTube\n",
    "# Remplace par des vraies URLs de vid√©os thermiques animali√®res\n",
    "YOUTUBE_URLS = [\n",
    "    # \"https://www.youtube.com/watch?v=...\",  # Safari thermique #1\n",
    "    # \"https://www.youtube.com/watch?v=...\",  # Documentaire FLIR wildlife\n",
    "    # \"https://www.youtube.com/watch?v=...\",  # Night vision animals\n",
    "]\n",
    "\n",
    "# D√©commenter pour lancer l'extraction\n",
    "total_frames = 0\n",
    "for i, url in enumerate(YOUTUBE_URLS):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Vid√©o {i+1}/{len(YOUTUBE_URLS)}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    frames = extract_frames_from_youtube(\n",
    "        url, \n",
    "        output_dir=f\"real_thermal_dataset/video_{i+1}\", \n",
    "        fps=0.5,  # 1 frame toutes les 2 secondes\n",
    "        max_frames=300\n",
    "    )\n",
    "    total_frames += frames\n",
    "\n",
    "print(f\"\\nTotal : {total_frames} frames extraites de {len(YOUTUBE_URLS)} vid√©os\")\n",
    "print(f\"Dossier : real_thermal_dataset/\")\n",
    "\n",
    "print(\"Script pr√™t. Ajoute des URLs YouTube dans YOUTUBE_URLS et d√©commente le code d'ex√©cution.\")\n",
    "print(\"Recherches sugg√©r√©es : 'thermal imaging safari', 'FLIR wildlife night', 'infrared animal detection'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d31d10",
   "metadata": {},
   "source": [
    "## üìπ Alternative Dataset - Extraction YouTube\n",
    "\n",
    "Le dataset thermique actuel est artificiel et produit des r√©sultats limit√©s. Une meilleure approche est d'extraire des frames de **vid√©os YouTube r√©elles** (safaris thermiques, documentaires animaliers FLIR, etc.)\n",
    "\n",
    "**Avantages :**\n",
    "- Images thermiques authentiques\n",
    "- Vari√©t√© de conditions (jour/nuit, m√©t√©o, distances)\n",
    "- Qualit√© cam√©ra professionnelle (FLIR, cam√©ras militaires)\n",
    "\n",
    "**Sources sugg√©r√©es :**\n",
    "- \"thermal imaging safari africa\"\n",
    "- \"FLIR thermal camera wildlife\"\n",
    "- \"infrared animal detection night\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PER_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
