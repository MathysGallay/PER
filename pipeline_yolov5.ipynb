{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a18c396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mathy\\Documents\\SI5\\PER\\models\n",
      "C:\\Users\\mathy\\Documents\\SI5\\PER\\models\\yolov5\n",
      "C:\\Users\\mathy\\Documents\\SI5\\PER\\models\\yolov5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov5'...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "%cd C:\\Users\\mathy\\Documents\\SI5\\PER\\models\n",
    "\n",
    "# Cloner YOLOv5 s'il n'existe pas déjà\n",
    "if not os.path.exists(\"yolov5\"):\n",
    "    !git clone https://github.com/ultralytics/yolov5\n",
    "\n",
    "%cd yolov5\n",
    "\n",
    "#!pip install -r requirements.txt onnx onnxruntime onnx_tf tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "669ac1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "print(\"Torch CUDA available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c18a4cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source exists: True\n",
      "Labels exist: True\n",
      "Images trouvées : 2500\n",
      "Train: 2000, Val: 500\n",
      "Dataset YOLO créé\n",
      "Dataset YOLO créé\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "SOURCE_DIR = r\"C:\\Users\\mathy\\Documents\\SI5\\PER\\thermal_coco\\augmented\"\n",
    "SOURCE_LABELS = r\"C:\\Users\\mathy\\Documents\\SI5\\PER\\mini_coco\\labels\"\n",
    "TARGET_DIR = \"thermal_yolo\"\n",
    "\n",
    "print(f\"Source exists: {os.path.exists(SOURCE_DIR)}\")\n",
    "print(f\"Labels exist: {os.path.exists(SOURCE_LABELS)}\")\n",
    "\n",
    "os.makedirs(TARGET_DIR, exist_ok=True)\n",
    "\n",
    "# YOLO folders\n",
    "folders = [\"images/train\", \"images/val\", \"labels/train\", \"labels/val\"]\n",
    "for f in folders:\n",
    "    os.makedirs(os.path.join(TARGET_DIR, f), exist_ok=True)\n",
    "\n",
    "# Récupérer toutes les images\n",
    "images = glob.glob(os.path.join(SOURCE_DIR, \"*.jpg\"))\n",
    "print(f\"Images trouvées : {len(images)}\")\n",
    "\n",
    "if len(images) == 0:\n",
    "    print(\"ERREUR : Aucune image trouvée!\")\n",
    "else:\n",
    "    # Train/val split\n",
    "    train_ratio = 0.8\n",
    "    random.shuffle(images)\n",
    "    split = int(len(images) * train_ratio)\n",
    "    \n",
    "    train_imgs = images[:split]\n",
    "    val_imgs = images[split:]\n",
    "    \n",
    "    print(f\"Train: {len(train_imgs)}, Val: {len(val_imgs)}\")\n",
    "    \n",
    "    # Copier train\n",
    "    for img_path in train_imgs:\n",
    "        img_name = os.path.basename(img_path)\n",
    "        shutil.copy(img_path, os.path.join(TARGET_DIR, \"images/train\", img_name))\n",
    "        \n",
    "        # Récupérer le label original (sans _aug)\n",
    "        base_name = img_name.split('_aug')[0] if '_aug' in img_name else img_name.replace('.jpg', '')\n",
    "        label_src = os.path.join(SOURCE_LABELS, base_name + '.txt')\n",
    "        label_dst = os.path.join(TARGET_DIR, \"labels/train\", img_name.replace('.jpg', '.txt'))\n",
    "        \n",
    "        if os.path.exists(label_src):\n",
    "            shutil.copy(label_src, label_dst)\n",
    "    \n",
    "    # Copier val\n",
    "    for img_path in val_imgs:\n",
    "        img_name = os.path.basename(img_path)\n",
    "        shutil.copy(img_path, os.path.join(TARGET_DIR, \"images/val\", img_name))\n",
    "        \n",
    "        base_name = img_name.split('_aug')[0] if '_aug' in img_name else img_name.replace('.jpg', '')\n",
    "        label_src = os.path.join(SOURCE_LABELS, base_name + '.txt')\n",
    "        label_dst = os.path.join(TARGET_DIR, \"labels/val\", img_name.replace('.jpg', '.txt'))\n",
    "        \n",
    "        if os.path.exists(label_src):\n",
    "            shutil.copy(label_src, label_dst)\n",
    "    \n",
    "    print(\"Dataset YOLO créé\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "26a446fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes animales : ['bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe']\n",
      "data.yaml généré !\n"
     ]
    }
   ],
   "source": [
    "# Classes animales uniquement (celles utilisées dans download_mini_coco_animals.py)\n",
    "ANIMAL_CLASSES = {\n",
    "    14: \"bird\",\n",
    "    15: \"cat\",\n",
    "    16: \"dog\",\n",
    "    17: \"horse\",\n",
    "    18: \"sheep\",\n",
    "    19: \"cow\",\n",
    "    20: \"elephant\",\n",
    "    21: \"bear\",\n",
    "    22: \"zebra\",\n",
    "    23: \"giraffe\",\n",
    "}\n",
    "\n",
    "classes = list(ANIMAL_CLASSES.values())\n",
    "print(f\"Classes animales : {classes}\")\n",
    "\n",
    "yaml_content = f\"\"\"\n",
    "train: {TARGET_DIR}/images/train\n",
    "val: {TARGET_DIR}/images/val\n",
    "\n",
    "nc: {len(classes)}\n",
    "names: {classes}\n",
    "\"\"\"\n",
    "\n",
    "with open(\"data.yaml\", \"w\") as f:\n",
    "    f.write(yaml_content)\n",
    "\n",
    "print(\"data.yaml généré !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce0bdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --img 256 --batch 16 --epochs 50 --weights yolov5n.pt --data data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6714f8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mexport: \u001b[0mdata=C:\\Users\\abdel\\Desktop\\SI5\\S2\\PER\\test_conversion_rgb_th\\yolov5\\data\\coco128.yaml, weights=['runs/train/thermal_yolov5n_256x192/weights/best.pt'], imgsz=[256], batch_size=1, device=cpu, half=False, inplace=False, keras=False, optimize=False, int8=False, per_tensor=False, dynamic=False, cache=, simplify=False, mlmodel=False, opset=17, verbose=False, workspace=4, nms=False, agnostic_nms=False, topk_per_class=100, topk_all=100, iou_thres=0.45, conf_thres=0.25, include=['onnx']\n",
      "YOLOv5  v7.0-448-gdeec5e45 Python-3.13.3 torch-2.9.1+cpu CPU\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"c:\\Users\\abdel\\Desktop\\SI5\\S2\\PER\\test_conversion_rgb_th\\yolov5\\export.py\"\u001b[0m, line \u001b[35m1525\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    \u001b[31mmain\u001b[0m\u001b[1;31m(opt)\u001b[0m\n",
      "    \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^\u001b[0m\n",
      "  File \u001b[35m\"c:\\Users\\abdel\\Desktop\\SI5\\S2\\PER\\test_conversion_rgb_th\\yolov5\\export.py\"\u001b[0m, line \u001b[35m1520\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "    \u001b[31mrun\u001b[0m\u001b[1;31m(**vars(opt))\u001b[0m\n",
      "    \u001b[31m~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"c:\\Users\\abdel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\_contextlib.py\"\u001b[0m, line \u001b[35m120\u001b[0m, in \u001b[35mdecorate_context\u001b[0m\n",
      "    return func(*args, **kwargs)\n",
      "  File \u001b[35m\"c:\\Users\\abdel\\Desktop\\SI5\\S2\\PER\\test_conversion_rgb_th\\yolov5\\export.py\"\u001b[0m, line \u001b[35m1365\u001b[0m, in \u001b[35mrun\u001b[0m\n",
      "    model = attempt_load(weights, device=device, inplace=True, fuse=True)  # load FP32 model\n",
      "  File \u001b[35m\"c:\\Users\\abdel\\Desktop\\SI5\\S2\\PER\\test_conversion_rgb_th\\yolov5\\models\\experimental.py\"\u001b[0m, line \u001b[35m98\u001b[0m, in \u001b[35mattempt_load\u001b[0m\n",
      "    ckpt = torch_load(attempt_download(w), map_location=\"cpu\")  # load\n",
      "  File \u001b[35m\"c:\\Users\\abdel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\ultralytics\\utils\\patches.py\"\u001b[0m, line \u001b[35m116\u001b[0m, in \u001b[35mtorch_load\u001b[0m\n",
      "    return \u001b[31mtorch.load\u001b[0m\u001b[1;31m(*args, **kwargs)\u001b[0m\n",
      "           \u001b[31m~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"c:\\Users\\abdel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\serialization.py\"\u001b[0m, line \u001b[35m1484\u001b[0m, in \u001b[35mload\u001b[0m\n",
      "    with \u001b[31m_open_file_like\u001b[0m\u001b[1;31m(f, \"rb\")\u001b[0m as opened_file:\n",
      "         \u001b[31m~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"c:\\Users\\abdel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\serialization.py\"\u001b[0m, line \u001b[35m759\u001b[0m, in \u001b[35m_open_file_like\u001b[0m\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "  File \u001b[35m\"c:\\Users\\abdel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\serialization.py\"\u001b[0m, line \u001b[35m740\u001b[0m, in \u001b[35m__init__\u001b[0m\n",
      "    super().__init__(\u001b[31mopen\u001b[0m\u001b[1;31m(name, mode)\u001b[0m)\n",
      "                     \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^\u001b[0m\n",
      "\u001b[1;35mFileNotFoundError\u001b[0m: \u001b[35m[Errno 2] No such file or directory: 'runs\\\\train\\\\thermal_yolov5n_256x192\\\\weights\\\\best.pt'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python export.py --weights runs/train/thermal_yolov5n_256x192/weights/best.pt --include onnx --imgsz 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd8d1656",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'mapping' from 'onnx' (c:\\Users\\abdel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\onnx\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01monnx_tf\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m prepare\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01monnx\u001b[39;00m\n\u001b[32m      4\u001b[39m model_onnx = onnx.load(\u001b[33m\"\u001b[39m\u001b[33mbest.onnx\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abdel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\onnx_tf\\__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m backend\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abdel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\onnx_tf\\backend.py:24\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01monnx_tf\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend_rep\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TensorflowRep\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01monnx_tf\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m data_type\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01monnx_tf\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m exception\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01monnx_tf\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_device_option\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abdel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\onnx_tf\\common\\data_type.py:4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumbers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Number\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01monnx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mapping\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01monnx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TensorProto\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'mapping' from 'onnx' (c:\\Users\\abdel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\onnx\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from onnx_tf.backend import prepare\n",
    "import onnx\n",
    "\n",
    "model_onnx = onnx.load(\"best.onnx\")\n",
    "tf_rep = prepare(model_onnx)\n",
    "tf_rep.export_graph(\"saved_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72e22b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"saved_model\")\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]  # INT8 quantization\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(\"model_int8.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"TFLite model saved as model_int8.tflite!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0a8314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_path=\"model_int8.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "def infer(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (256,192))\n",
    "    img = img[..., ::-1]  # BGR → RGB\n",
    "    img = img / 255.0\n",
    "    img = np.expand_dims(img.astype(np.float32), axis=0)\n",
    "\n",
    "    interpreter.set_tensor(input_details[0]['index'], img)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "    print(\"Output shape:\", output.shape)\n",
    "    return output\n",
    "\n",
    "# EXEMPLE\n",
    "# infer(\"../thermal_dataset/images/val/test.jpg\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PER_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
